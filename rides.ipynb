{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Ecobici data**\n",
    "\n",
    "Trabajando con datos abiertos del gobierno de CABA referidos a recorridos/viajes realizados en las biciclietas del sistema de Bike Sharing de CABA, \"EcoBici\". Los datos comprenden el periodo 2010-2019."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .appName(\"ecobici\") \\\n",
    "        .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los archivos no mantienen un esquema homogéneo entre sí. Tienen diferentes números y nombres de columna.\n",
    "\n",
    "Previamente, se ha trabajado para descartar algunas columnas y obtener un archivo JSON con los nombres de las columnas para uno de los archivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'recorridos-realizados-2010.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2011.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2012.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'lat_estacion_destino',\n",
       "  'long_estacion_destino'],\n",
       " 'recorridos-realizados-2013.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2014.csv': ['origen_recorrido_fecha',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'destino_recorrido_fecha',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2015.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2016.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2017.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2018.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'long_estacion_destino',\n",
       "  'lat_estacion_destino'],\n",
       " 'recorridos-realizados-2019.csv': ['fecha_origen_recorrido',\n",
       "  'id_estacion_origen',\n",
       "  'lat_estacion_origen',\n",
       "  'long_estacion_origen',\n",
       "  'duracion_recorrido',\n",
       "  'fecha_destino_recorrido',\n",
       "  'id_estacion_destino',\n",
       "  'lat_estacion_destino',\n",
       "  'long_estacion_destino']}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"files_schema.json\", \"r\") as json_file:\n",
    "    columns_per_files = json.load(json_file)\n",
    "columns_per_files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Null values**\n",
    "Primero contaremos los valores nulos para cada una de las columnas de cada archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recorridos-realizados-2010.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 3\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "recorridos-realizados-2011.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 85\n",
      "Column: long_estacion_origen\t Nulls: 85\n",
      "Column: lat_estacion_origen\t Nulls: 85\n",
      "Column: duracion_recorrido\t Nulls: 148\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 178\n",
      "Column: long_estacion_destino\t Nulls: 178\n",
      "Column: lat_estacion_destino\t Nulls: 178\n",
      "recorridos-realizados-2012.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 2487\n",
      "Column: lat_estacion_origen\t Nulls: 2487\n",
      "Column: long_estacion_origen\t Nulls: 2487\n",
      "Column: duracion_recorrido\t Nulls: 652\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 2849\n",
      "Column: lat_estacion_destino\t Nulls: 2849\n",
      "Column: long_estacion_destino\t Nulls: 2849\n",
      "recorridos-realizados-2013.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 35156\n",
      "Column: long_estacion_origen\t Nulls: 35156\n",
      "Column: lat_estacion_origen\t Nulls: 35156\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 37089\n",
      "Column: long_estacion_destino\t Nulls: 37089\n",
      "Column: lat_estacion_destino\t Nulls: 37089\n",
      "recorridos-realizados-2014.csv\n",
      "Column: origen_recorrido_fecha\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 123064\n",
      "Column: long_estacion_origen\t Nulls: 123064\n",
      "Column: lat_estacion_origen\t Nulls: 123064\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: destino_recorrido_fecha\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 131550\n",
      "Column: long_estacion_destino\t Nulls: 131550\n",
      "Column: lat_estacion_destino\t Nulls: 131550\n",
      "recorridos-realizados-2015.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 3168\n",
      "Column: lat_estacion_origen\t Nulls: 3168\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 3462\n",
      "Column: lat_estacion_destino\t Nulls: 3462\n",
      "recorridos-realizados-2016.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 93555\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "recorridos-realizados-2017.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 3419\n",
      "Column: long_estacion_origen\t Nulls: 3419\n",
      "Column: lat_estacion_origen\t Nulls: 3419\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 544906\n",
      "Column: id_estacion_destino\t Nulls: 3496\n",
      "Column: long_estacion_destino\t Nulls: 3496\n",
      "Column: lat_estacion_destino\t Nulls: 3496\n",
      "recorridos-realizados-2018.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 30224\n",
      "Column: long_estacion_origen\t Nulls: 30224\n",
      "Column: lat_estacion_origen\t Nulls: 30224\n",
      "Column: duracion_recorrido\t Nulls: 43723\n",
      "Column: fecha_destino_recorrido\t Nulls: 43723\n",
      "Column: id_estacion_destino\t Nulls: 30486\n",
      "Column: long_estacion_destino\t Nulls: 30486\n",
      "Column: lat_estacion_destino\t Nulls: 30486\n",
      "recorridos-realizados-2019.csv\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 14621\n",
      "Column: lat_estacion_origen\t Nulls: 16764\n",
      "Column: long_estacion_origen\t Nulls: 16764\n",
      "Column: duracion_recorrido\t Nulls: 145\n",
      "Column: fecha_destino_recorrido\t Nulls: 145\n",
      "Column: id_estacion_destino\t Nulls: 14719\n",
      "Column: lat_estacion_destino\t Nulls: 17017\n",
      "Column: long_estacion_destino\t Nulls: 17017\n"
     ]
    }
   ],
   "source": [
    "for file, columns in columns_per_files.items():\n",
    "    print(file)\n",
    "    rides = spark.read.csv(file, header=True)\n",
    "    rides = rides.select(*columns)\n",
    "    for column in columns:\n",
    "        print(f\"Column: {column}\\t Nulls: {rides.filter(F.isnull(column)).count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El análisis de estos valores nulos se puede separar de acuerdo a grupos de columnas.\n",
    "\n",
    "Con respecto a los campos ***id_estacion***, ***lat*** y ***long*** (tanto para la estación origen como destino): Mantienen el mismo número de valores nulos entre sí, podemos borrar aquellas filas con valores nulos para el campo id_estacion (ya sea origen o destino) ya que sin ese id no es posible obtener otros datos de la estacion.\n",
    "\n",
    "Sobre los campos ***fechas*** y ***duración*** del recorrido: Todos los archivos tienen una fecha de origen del recorrido. Si hay filas con valores nulos para los campos duracion y fecha de destino del recorrido, se descartan. Si solo una de esas fuese nula, es posible calcular mediante las funciones que correspondan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Reordering columns**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hay un archivo que presenta un nombre diferente a los demás para los campos sobre *fecha*, se lo corregirá para que coincida con el nombre de los otros archivos.\n",
    "Luego, con respecto a los campos de *latitud* y *longitud*, no mantienen el mismo orden entre los archivos, algunos presentan *(lat, long)* y otros *(long, lat)*, también se corregirá para que se presentan en este orden *(lat, long)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recorridos-realizados-2010.csv []\n",
      "recorridos-realizados-2011.csv []\n",
      "recorridos-realizados-2012.csv []\n",
      "recorridos-realizados-2013.csv []\n",
      "recorridos-realizados-2014.csv ['origen_recorrido_fecha', 'destino_recorrido_fecha']\n",
      "recorridos-realizados-2015.csv []\n",
      "recorridos-realizados-2016.csv []\n",
      "recorridos-realizados-2017.csv []\n",
      "recorridos-realizados-2018.csv []\n",
      "recorridos-realizados-2019.csv []\n"
     ]
    }
   ],
   "source": [
    "for file, columns in columns_per_files.items():\n",
    "    print(file, \\\n",
    "          list(filter(lambda x: x.startswith(\"origen\") or \\\n",
    "                      x.startswith(\"destino\"), columns)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordered_columns = columns_per_files[\"recorridos-realizados-2019.csv\"] # Columnas ordenadas que todos los archivos deben seguir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for fname in columns_per_files.keys():\n",
    "    rides = spark.read.csv(fname, header=True)\n",
    "    if fname.endswith(\"2014.csv\"):\n",
    "        rides = rides.withColumnRenamed(\"origen_recorrido_fecha\", \\\n",
    "                                        \"fecha_origen_recorrido\") \\\n",
    "                    .withColumnRenamed(\"destino_recorrido_fecha\", \\\n",
    "                                       \"fecha_destino_recorrido\")\n",
    "    rides = rides.select(*ordered_columns)\n",
    "    tablename = f\"rides{fname[-8:-4]}\" # 'rides' string + year\n",
    "    rides.write.saveAsTable(tablename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Deleting null values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = [f\"rides201{i}\" for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides2010\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 3\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2011\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 147\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2012\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 615\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2013\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2014\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2015\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 3168\n",
      "Column: long_estacion_origen\t Nulls: 3168\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 3462\n",
      "Column: long_estacion_destino\t Nulls: 3462\n",
      "rides2016\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 93555\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2017\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 540572\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2018\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2019\n",
      "Columns to inspect: ['id_estacion_origen', 'lat_estacion_origen', 'long_estacion_origen']\n",
      "Columns to inspect: ['id_estacion_destino', 'lat_estacion_destino', 'long_estacion_destino']\n",
      "Columns to inspect: ['duracion_recorrido', 'fecha_destino_recorrido']\n",
      "Column: fecha_origen_recorrido\t Nulls: 0\n",
      "Column: id_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_origen\t Nulls: 2135\n",
      "Column: long_estacion_origen\t Nulls: 2135\n",
      "Column: duracion_recorrido\t Nulls: 0\n",
      "Column: fecha_destino_recorrido\t Nulls: 0\n",
      "Column: id_estacion_destino\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 2167\n",
      "Column: long_estacion_destino\t Nulls: 2167\n"
     ]
    }
   ],
   "source": [
    "for tname in table_names:\n",
    "    print(tname)\n",
    "    rides = spark.table(tname)\n",
    "    \n",
    "    # Deleting rows about origin station\n",
    "    cols = rides.columns[1:4]\n",
    "    print(f\"Columns to inspect: {cols}\")\n",
    "    rides = rides.dropna(how=\"all\", subset=cols)\n",
    "    \n",
    "    # Deleting rows about target station\n",
    "    cols = rides.columns[6:]\n",
    "    print(f\"Columns to inspect: {cols}\")\n",
    "    rides = rides.dropna(how=\"all\", subset=cols)\n",
    "    \n",
    "    # Deleting rows about date and duration ride\n",
    "    cols = rides.columns[4:6]\n",
    "    print(f\"Columns to inspect: {cols}\")\n",
    "    rides = rides.dropna(how=\"all\", subset=cols)\n",
    "    \n",
    "    for column in columns:\n",
    "        print(f\"Column: {column}\\t Nulls: {rides.filter(F.isnull(column)).count()}\")\n",
    "    \n",
    "    # Dataframe to table\n",
    "    rides.write.saveAsTable(\"temp\")\n",
    "    spark.table(\"temp\") \\\n",
    "            .write.insertInto(tname, overwrite=True)\n",
    "    spark.sql(\"DROP TABLE IF EXISTS temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Filling nulls values**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def change_column_dtype(df, column, new_dtype):\n",
    "    df = df.withColumn(column, \\\n",
    "                             df[column] \\\n",
    "                              .cast(new_dtype) \\\n",
    "                              .alias(column))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se cuenta con un dataset con datos como id, nombre, latitud, longitud, direccion, etc. de cada estacion de ecobici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat long nombre_estacion id_estacion capacidad dirección_completa direccion_nombre direccion_altura direccion_interseccion barrio\n"
     ]
    }
   ],
   "source": [
    "stations = spark.read.csv(\"estaciones-bicicletas-publicas.csv\", header=True)\n",
    "stations = stations.repartition(1)\n",
    "# stations.rdd.getNumPartitions()\n",
    "print(*stations.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id_estacion', 'int')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = change_column_dtype(stations, \"id_estacion\", \"int\")\n",
    "stations.select(\"id_estacion\").dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero trabajaremos con los campos referidos a **latitud** y **longitud**, donde solo los archivos de los años 2015 y 2019 presentaban valores nulos en dichos campos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides2015\n",
      "+------------------+\n",
      "|id_estacion_origen|\n",
      "+------------------+\n",
      "|                15|\n",
      "|                39|\n",
      "+------------------+\n",
      "\n",
      "+-------------------+\n",
      "|id_estacion_destino|\n",
      "+-------------------+\n",
      "|                 15|\n",
      "|                 39|\n",
      "+-------------------+\n",
      "\n",
      "rides2019\n",
      "+------------------+\n",
      "|id_estacion_origen|\n",
      "+------------------+\n",
      "|             159_0|\n",
      "|              44_0|\n",
      "+------------------+\n",
      "\n",
      "+-------------------+\n",
      "|id_estacion_destino|\n",
      "+-------------------+\n",
      "|              159_0|\n",
      "|               44_0|\n",
      "+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for year in [\"2015\", \"2019\"]:\n",
    "    print(f\"rides{year}\")\n",
    "    rides = spark.table(f\"rides{year}\")\n",
    "    rides.filter(F.isnull(\"lat_estacion_origen\") & \\\n",
    "                F.isnull(\"long_estacion_origen\")) \\\n",
    "        .select(\"id_estacion_origen\").distinct().show()\n",
    "    \n",
    "    rides.filter(F.isnull(\"lat_estacion_destino\") & \\\n",
    "                F.isnull(\"long_estacion_destino\")) \\\n",
    "        .select(\"id_estacion_destino\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Respecto a los particulares ids \"159_0\" y \"44_0\", los verificaremos con el dataset de estaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+\n",
      "|id_estacion|\n",
      "+-----------+\n",
      "|         15|\n",
      "|         39|\n",
      "|         44|\n",
      "+-----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "stations.filter((stations.id_estacion == 15) | (stations.id_estacion == 39) | \\\n",
    "               (stations.id_estacion == 159) | (stations.id_estacion == 44) | \\\n",
    "               (stations.id_estacion == \"44_0\") | (stations.id_estacion == \"159_0\")) \\\n",
    "        .select(\"id_estacion\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La estacion de id \"159_0\" o 159 no existe, se puede descartar las filas con ese valor.\n",
    "Luego, nos aseguramos que el valor de id \"44_0\", corresponde a 44."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------+\n",
      "|nombre_estacion_origen|\n",
      "+----------------------+\n",
      "|             Ecoparque|\n",
      "+----------------------+\n",
      "only showing top 1 row\n",
      "\n",
      "+---------------+\n",
      "|nombre_estacion|\n",
      "+---------------+\n",
      "|044 - Ecoparque|\n",
      "+---------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "spark.read.csv(\"recorridos-realizados-2019.csv\", header=True) \\\n",
    ".filter(\"id_estacion_origen = '44_0'\") \\\n",
    ".select(\"nombre_estacion_origen\").show(1)\n",
    "\n",
    "stations.filter(\"id_estacion == 44\").select(\"nombre_estacion\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Efectivamente, coinciden. Ahora continuamos con los tratamientos correspondientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "rides = spark.table(\"rides2019\")\n",
    "rides = rides.replace(\"44_0\", \"44\", subset=[\"id_estacion_origen\", \"id_estacion_destino\"])\n",
    "rides = change_column_dtype(rides, \"id_estacion_origen\", \"int\")\n",
    "rides = change_column_dtype(rides, \"id_estacion_destino\", \"int\")\n",
    "rides = rides.na.drop(how=\"any\", subset=[\"id_estacion_origen\", \"id_estacion_destino\"])\n",
    "rides.write.saveAsTable(\"temp\")\n",
    "spark.table(\"temp\").write.insertInto(\"rides2019\", overwrite=True)\n",
    "_ = spark.sql(\"DROP TABLE IF EXISTS temp\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, ya podemos completar los valores nulos para los campos de latidad y longitud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filling_geographical_fields(rides_df, stations_df, coord_type, station_type):\n",
    "    \"\"\"\n",
    "    coord_type: lat/long\n",
    "    station_type: origen/destino\n",
    "    \"\"\"\n",
    "    stations_df = stations_df.select(*[\"id_estacion\", \"lat\", \"long\"])\n",
    "    stations_df = stations_df.withColumnRenamed(\"id_estacion\", \\\n",
    "                                                f\"id_estacion_{station_type}\")\n",
    "    \n",
    "    joined_df = rides_df.join(stations_df, on=f\"id_estacion_{station_type}\")\n",
    "    joined_df = joined_df.withColumn(f\"{coord_type}_estacion_{station_type}\", \\\n",
    "                                F.coalesce(joined_df[f\"{coord_type}_estacion_{station_type}\"], \\\n",
    "                                          joined_df[coord_type]))\n",
    "    joined_df = joined_df.drop(\"lat\", \"long\")\n",
    "    return joined_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides2015\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n",
      "rides2019\n",
      "Column: lat_estacion_origen\t Nulls: 0\n",
      "Column: long_estacion_origen\t Nulls: 0\n",
      "Column: lat_estacion_destino\t Nulls: 0\n",
      "Column: long_estacion_destino\t Nulls: 0\n"
     ]
    }
   ],
   "source": [
    "for year in [\"2015\", \"2019\"]:\n",
    "    rides = spark.table(f\"rides{year}\")\n",
    "    ordered_cols = rides.columns\n",
    "    for station_type in [\"origen\", \"destino\"]:\n",
    "        for coord_type in [\"lat\", \"long\"]:\n",
    "            rides = filling_geographical_fields(rides, stations, coord_type, station_type)\n",
    "            \n",
    "    print(f\"rides{year}\")\n",
    "    for column in rides.columns:\n",
    "        if 'lat' in column or 'long' in column:\n",
    "            print(f\"Column: {column}\\t Nulls: {rides.filter(F.isnull(column)).count()}\")\n",
    "    \n",
    "    rides = rides.select(ordered_columns)\n",
    "    rides.write.saveAsTable(\"temp\", mode=\"overwrite\")\n",
    "    spark.table(\"temp\").write.insertInto(f\"rides{year}\", overwrite=True)\n",
    "    spark.sql(\"DROP TABLE temp\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Fechas y duracion**\n",
    "Hechemos un vistazo al formato de los datos de fecha y duración"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides2010\n",
      "rides2011\n",
      "rides2012\n",
      "rides2013\n",
      "rides2014\n",
      "rides2015\n",
      "rides2016\n",
      "rides2017\n",
      "rides2018\n",
      "rides2019\n"
     ]
    }
   ],
   "source": [
    "for tname in table_names:\n",
    "    print(tname)\n",
    "    rides = spark.read.parquet(f\"spark-warehouse2/{tname}/*\")\n",
    "    rides.write.saveAsTable(tname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides2010\n",
      "+----------------------+-----------------------+------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|duracion_recorrido|\n",
      "+----------------------+-----------------------+------------------+\n",
      "|      30/12/2010 19:39|       30/12/2010 19:46|               7.0|\n",
      "|      30/12/2010 19:34|       30/12/2010 19:47|              13.0|\n",
      "|      30/12/2010 19:10|       30/12/2010 19:17|               7.0|\n",
      "|      30/12/2010 19:03|       30/12/2010 19:29|              26.0|\n",
      "|      30/12/2010 19:02|       30/12/2010 19:13|              11.0|\n",
      "+----------------------+-----------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2011\n",
      "+----------------------+-----------------------+------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|duracion_recorrido|\n",
      "+----------------------+-----------------------+------------------+\n",
      "|   2011-09-29 19:40:00|       29/09/2011 19:49|              10.0|\n",
      "|   2011-09-29 19:37:00|       29/09/2011 19:57|              20.0|\n",
      "|   2011-09-29 19:36:00|       29/09/2011 19:41|               5.0|\n",
      "|   2011-09-29 19:35:00|       29/09/2011 19:49|              13.0|\n",
      "|   2011-09-29 19:34:00|       29/09/2011 20:07|              34.0|\n",
      "+----------------------+-----------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2012\n",
      "+----------------------+-----------------------+------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|duracion_recorrido|\n",
      "+----------------------+-----------------------+------------------+\n",
      "|  2012-01-02 07:42:...|   2012-01-02 08:10:...|              29.0|\n",
      "|  2012-01-02 07:58:...|   2012-01-02 08:16:...|              19.0|\n",
      "|  2012-01-02 07:59:...|   2012-01-02 08:25:...|              26.0|\n",
      "|  2012-01-02 08:01:...|   2012-01-02 08:18:...|              17.0|\n",
      "|  2012-01-02 08:05:...|   2012-01-02 08:32:...|              27.0|\n",
      "+----------------------+-----------------------+------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2013\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|  2013-01-02 07:49:...|   2013-01-02 08:11:...|0 days 00:21:43.7...|\n",
      "|  2013-01-02 07:52:...|   2013-01-02 08:23:...|0 days 00:30:49.5...|\n",
      "|  2013-01-02 07:53:...|   2013-01-02 08:25:...|0 days 00:31:08.1...|\n",
      "|  2013-01-02 07:54:...|   2013-01-02 08:54:...|0 days 00:59:34.1...|\n",
      "|  2013-01-02 07:55:...|   2013-01-02 08:13:...|0 days 00:18:21.0...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2014\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|  2014-06-25 18:20:...|   2014-06-25 18:43:...|0 days 00:22:42.1...|\n",
      "|  2014-06-25 18:21:...|   2014-06-25 18:57:...|0 days 00:36:06.4...|\n",
      "|  2014-06-25 18:21:...|   2014-06-25 18:38:...|0 days 00:17:06.5...|\n",
      "|  2014-06-25 18:21:...|   2014-06-25 18:38:...|0 days 00:16:50.3...|\n",
      "|  2014-06-25 18:21:...|   2014-06-25 18:42:...|0 days 00:20:44.9...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2015\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|   2015-09-16 18:05:11|    2015-09-16 19:12:15|0 days 01:07:04.0...|\n",
      "|   2015-09-16 18:05:23|    2015-09-16 18:15:53|0 days 00:10:30.0...|\n",
      "|   2015-09-16 18:05:23|    2015-09-16 18:59:45|0 days 00:54:22.0...|\n",
      "|   2015-09-16 18:05:31|    2015-09-16 18:44:27|0 days 00:38:56.0...|\n",
      "|   2015-09-16 18:05:56|    2015-09-16 18:59:31|0 days 00:53:35.0...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2016\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|   2016-09-09 20:43:40|    2016-09-09 21:19:19|0 days 00:15:33.0...|\n",
      "|   2016-09-09 20:43:53|    2016-09-09 21:10:35|0 days 00:30:43.0...|\n",
      "|   2016-09-09 20:44:20|    2016-09-09 21:06:06|0 days 00:33:30.0...|\n",
      "|   2016-09-09 20:44:52|    2016-09-09 20:54:58|0 days 00:15:56.0...|\n",
      "|   2016-09-09 20:45:09|    2016-09-09 21:10:48|0 days 00:10:06.0...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2017\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|   2017-01-01 00:02:14|    2017-01-01 00:28:38|0 days 00:27:44.0...|\n",
      "|   2017-01-01 00:02:59|    2017-01-01 01:00:52|0 days 01:57:21.0...|\n",
      "|   2017-01-01 00:07:13|    2017-01-01 01:10:21|0 days 00:25:08.0...|\n",
      "|   2017-01-01 00:15:12|    2017-01-01 01:19:30|0 days 00:33:39.0...|\n",
      "|   2017-01-01 00:15:27|    2017-01-01 01:25:08|0 days 00:20:23.0...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2018\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|   2018-01-01 00:08:05|    2018-01-01 00:27:58|0 days 00:19:53.0...|\n",
      "|   2018-01-01 00:18:05|    2018-01-01 00:44:24|0 days 00:26:19.0...|\n",
      "|   2018-01-01 00:20:14|    2018-01-01 00:47:53|0 days 00:27:39.0...|\n",
      "|   2018-01-01 00:20:22|    2018-01-01 01:09:13|0 days 00:48:51.0...|\n",
      "|   2018-01-01 00:20:31|    2018-01-01 01:09:58|0 days 00:49:27.0...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "rides2019\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|fecha_origen_recorrido|fecha_destino_recorrido|  duracion_recorrido|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "|   2019-05-28 17:22:34|    2019-05-28 17:36:07|0 days 00:13:33.0...|\n",
      "|   2019-05-28 17:22:36|    2019-05-28 17:56:42|0 days 00:34:06.0...|\n",
      "|   2019-05-28 17:22:38|    2019-05-28 17:51:41|0 days 00:29:03.0...|\n",
      "|   2019-05-28 17:22:39|    2019-05-28 17:35:22|0 days 00:12:43.0...|\n",
      "|   2019-05-28 17:22:40|    2019-05-28 17:36:40|0 days 00:14:00.0...|\n",
      "+----------------------+-----------------------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for table in table_names:\n",
    "    rides = spark.table(table)\n",
    "    date_columns = list(filter(lambda column: 'fecha' in column, rides.columns))\n",
    "    dates = rides.select(date_columns+['duracion_recorrido'])\n",
    "    print(table)\n",
    "    dates.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Formatos los valores de campos sobre fecha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_date(column):\n",
    "    formats = [\"yyyy-MM-dd HH:mm\", \"dd/MM/yyyy HH:mm\"]\n",
    "    return F.coalesce(F.to_timestamp(column, formats[0]), \\\n",
    "                     F.to_timestamp(column, formats[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_in_minutes(start_date, end_date):\n",
    "    \"\"\"\n",
    "    Return the difference in minutes between end_date and start_date\n",
    "    \"\"\"\n",
    "    diff = (F.col(end_date).cast(\"long\") - F.col(start_date).cast(\"long\")) / 60\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def duration_in_minutes(df, duration_col):\n",
    "    \"\"\"\n",
    "    turn ride duration in minutes\n",
    "    \"\"\"\n",
    "    df = df.withColumn(\"duration_days\", \\\n",
    "                      F.split(duration_col, \"days\").getItem(0))\n",
    "    df = df.withColumn(\"hour\", \\\n",
    "                      F.split(duration_col, \"days\").getItem(1))\n",
    "    df = df.withColumn(\"hour\", \\\n",
    "                      F.split(\"hour\", \":\"))\n",
    "    df = df.withColumn(duration_col, \\\n",
    "                      F.col(\"duration_days\")*1440 + \\\n",
    "                      F.col(\"hour\").getItem(0)*60 + \\\n",
    "                       F.col(\"hour\").getItem(1))\n",
    "    df = df.drop(\"duration_days\", \"hour\")\n",
    "    df = df.withColumn(duration_col, \\\n",
    "                      F.col(duration_col).cast(\"int\"))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rides2010\n",
      "rides2011\n",
      "rides2012\n",
      "rides2013\n",
      "rides2014\n",
      "rides2015\n",
      "rides2016\n",
      "rides2017\n",
      "rides2018\n",
      "rides2019\n"
     ]
    }
   ],
   "source": [
    "for tname in table_names:\n",
    "    print(tname)\n",
    "    rides = spark.table(tname)\n",
    "    \n",
    "    for id_estacion in [\"id_estacion_origen\", \"id_estacion_destino\"]:\n",
    "        rides = change_column_dtype(rides, id_estacion, \"int\")\n",
    "    \n",
    "    for date_col in [\"fecha_origen_recorrido\", \"fecha_destino_recorrido\"]:\n",
    "        rides = rides.withColumn(date_col, \\\n",
    "                                format_date(date_col))\n",
    "        \n",
    "    # Calcular la duracion del recorrido donde hay valores nulos\n",
    "    if tname in [\"rides2010\", \"rides2011\", \"rides2012\"]:\n",
    "        rides = rides.withColumn(\"duracion_recorrido\", \\\n",
    "                                F.coalesce(\"duracion_recorrido\", \\\n",
    "                                          diff_in_minutes(\"fecha_origen_recorrido\", \\\n",
    "                                                         \"fecha_destino_recorrido\")))\n",
    "        rides = change_column_dtype(rides, \"duracion_recorrido\", \"int\")\n",
    "    \n",
    "    else:\n",
    "        rides = duration_in_minutes(rides, \"duracion_recorrido\")\n",
    "    \n",
    "    # Calcular la fecha de destino donde hay valores nulos\n",
    "    if tname in [\"rides2016\", \"rides2017\"]:\n",
    "        rides = rides.withColumn(\"fecha_destino_recorrido\", \\\n",
    "                         F.coalesce(\"fecha_destino_recorrido\", \\\n",
    "                                   F.from_unixtime( \\\n",
    "                                                   F.expr(\"to_unix_timestamp(fecha_origen_recorrido, 'yyyy-MM-dd HH:mm:ss') \\\n",
    "                                                   + (duracion_recorrido * 60)\")).cast(\"timestamp\")))   \n",
    "    \n",
    "    rides.write.option(\"path\", \"/home/jovyan/ecobici_rides/tables/\") \\\n",
    "        .saveAsTable(\"all_tables\", mode=\"append\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos en campos diferentes la fecha y la hora del recorrido"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "rides = spark.table(\"all_tables\")\n",
    "date_columns = [\"fecha_origen_recorrido\", \"fecha_destino_recorrido\"]\n",
    "hour_columns = [\"hora_partida\", \"hora_llegada\"]\n",
    "\n",
    "for date_col, hour_col in zip(date_columns, hour_columns):\n",
    "    rides = rides.withColumn(\"date_and_hour\", F.split(date_col, \" \"))\n",
    "    rides = rides.withColumn(date_col, \\\n",
    "                    rides[\"date_and_hour\"].getItem(0).cast(\"date\"))\n",
    "    rides = rides.withColumn(hour_col, \\\n",
    "                            rides[\"date_and_hour\"].getItem(1))\n",
    "    rides = rides.withColumn(hour_col, \\\n",
    "                            F.substring(hour_col, 1, 5))\n",
    "    rides = rides.drop(\"date_and_hour\")\n",
    "\n",
    "rides.select(*date_columns, *hour_columns, \"duracion_recorrido\").show(5)\n",
    "#rides.write.saveAsTable(\"temp\")\n",
    "#spark.table(\"temp\").write.saveAsTable(\"all_tables\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
